<!-- public/index.html -->
<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Vaisight OCR</title>
</head>
<body>
  <h2>Vaisight Price Reader</h2>
  <video id="video" autoplay playsinline style="width: 100%; max-height: 300px;"></video>
  <canvas id="canvas" style="display: none;"></canvas>
  <div id="output"></div>

  <script>
    const video = document.getElementById('video');
    const canvas = document.getElementById('canvas');
    const ctx = canvas.getContext('2d');
    const output = document.getElementById('output');

    async function startCamera() {
      const stream = await navigator.mediaDevices.getUserMedia({ video: { facingMode: 'environment' } });
      video.srcObject = stream;
    }

    async function captureAndSendFrame() {
      canvas.width = video.videoWidth;
      canvas.height = video.videoHeight;
      ctx.drawImage(video, 0, 0);
      canvas.toBlob(async (blob) => {
        const formData = new FormData();
        formData.append('frame', blob, 'frame.jpg');

        try {
          const res = await fetch('/ocr-frame', {
            method: 'POST',
            body: formData
          });
          const data = await res.json();
          if (data.text) {
            output.innerText = `Price: ${data.text}`;
            const msg = new SpeechSynthesisUtterance(`Price is ${data.text}`);
            speechSynthesis.speak(msg);
          }
        } catch (err) {
          console.error('OCR request failed:', err);
        }
      }, 'image/jpeg', 0.7);
    }

    startCamera();
    setInterval(captureAndSendFrame, 2000);
  </script>
</body>
</html>
